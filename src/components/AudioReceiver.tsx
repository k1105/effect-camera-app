import {useEffect, useRef, useState} from "react";

// ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
const CONFIG = {
  BASE_FREQ: 17000, // åŸºæœ¬å‘¨æ³¢æ•°
  FREQ_RANGE: 2000, // å‘¨æ³¢æ•°ç¯„å›²
  NUM_CHANNELS: 32, // ãƒãƒ£ãƒ³ãƒãƒ«æ•°
  SIGNAL_DURATION: 1.0, // ä¿¡å·é•·ï¼ˆç§’ï¼‰
  SAMPLE_RATE: 44100, // ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
  FFT_SIZE: 1024, // FFT ã‚µã‚¤ã‚º
  DETECTION_THRESHOLD: 0.3, // æ¤œå‡ºé–¾å€¤
  SMOOTHING: 0.8, // ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ä¿‚æ•°
};

interface AudioReceiverProps {
  onEffectDetected: (effectId: number) => void;
  availableEffects: number; // åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ•ã‚§ã‚¯ãƒˆã®æ•°ã‚’è¿½åŠ 
}

// WebKitAudioContextã®å‹å®šç¾©
declare global {
  interface Window {
    webkitAudioContext: typeof AudioContext;
  }
}

export function AudioReceiver({
  onEffectDetected,
  availableEffects,
}: AudioReceiverProps) {
  const [isReceiving, setIsReceiving] = useState(false);
  const [detectedFrequency, setDetectedFrequency] = useState<number>(0);
  const [signalStrength, setSignalStrength] = useState<number>(0);
  const [status, setStatus] = useState<string>("å¾…æ©Ÿä¸­");
  const [lastDetectedChannel, setLastDetectedChannel] = useState<number>(-1);

  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const microphoneRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const filterRef = useRef<BiquadFilterNode | null>(null);
  const detectionIntervalRef = useRef<number | null>(null);
  const lastDetectedEffectRef = useRef<number>(-1);
  const effectCooldownRef = useRef<boolean>(false);

  // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¦æ±‚
  const requestMicrophoneAccess = async () => {
    try {
      setStatus("ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¦æ±‚ä¸­...");

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: CONFIG.SAMPLE_RATE,
          channelCount: 1,
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
        },
      });

      // AudioContextã®ä½œæˆ
      const AudioContextClass =
        window.AudioContext || window.webkitAudioContext;
      audioContextRef.current = new AudioContextClass({
        sampleRate: CONFIG.SAMPLE_RATE,
      });

      microphoneRef.current =
        audioContextRef.current.createMediaStreamSource(stream);

      // ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®è¨­å®š
      filterRef.current = audioContextRef.current.createBiquadFilter();
      filterRef.current.type = "highpass";
      // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
      const filter = filterRef.current;
      filter.Q.value = 1;
      filter.frequency.value = 10000;
      filter.gain.value = 40;

      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = CONFIG.FFT_SIZE;
      analyserRef.current.smoothingTimeConstant = CONFIG.SMOOTHING;

      microphoneRef.current.connect(filterRef.current);
      filterRef.current.connect(analyserRef.current);

      setStatus("ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯å®Œäº† - å—ä¿¡æº–å‚™å®Œäº†");
      return true;
    } catch (error) {
      console.error("ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:", error);
      setStatus("ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ");
      return false;
    }
  };

  // å‘¨æ³¢æ•°è¨ˆç®—
  const getFrequencyForChannel = (channel: number) => {
    const step = CONFIG.FREQ_RANGE / CONFIG.NUM_CHANNELS;
    return CONFIG.BASE_FREQ + channel * step;
  };

  // æ¤œå‡ºãƒ«ãƒ¼ãƒ—é–‹å§‹
  const startDetectionLoop = () => {
    if (!analyserRef.current) return;

    const bufferLength = analyserRef.current.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    detectionIntervalRef.current = window.setInterval(() => {
      if (!analyserRef.current) return;

      analyserRef.current.getByteFrequencyData(dataArray);

      let maxIntensity = 0;
      let detectedChannel = -1;
      let detectedFrequency = 0;

      // å„ãƒãƒ£ãƒ³ãƒãƒ«ã®å¼·åº¦ã‚’ãƒã‚§ãƒƒã‚¯
      for (let channel = 0; channel < CONFIG.NUM_CHANNELS; channel++) {
        const frequency = getFrequencyForChannel(channel);
        const binIndex = Math.round(
          (frequency * CONFIG.FFT_SIZE) / CONFIG.SAMPLE_RATE
        );

        if (binIndex < bufferLength) {
          let intensity = 0;
          const range = 2;
          for (let i = -range; i <= range; i++) {
            const idx = binIndex + i;
            if (idx >= 0 && idx < bufferLength) {
              intensity += dataArray[idx];
            }
          }
          intensity = intensity / (range * 2 + 1) / 255.0;

          if (
            intensity > CONFIG.DETECTION_THRESHOLD &&
            intensity > maxIntensity
          ) {
            maxIntensity = intensity;
            detectedChannel = channel;
            detectedFrequency = frequency;
          }
        }
      }

      // UIæ›´æ–°
      setDetectedFrequency(detectedFrequency);
      setSignalStrength(maxIntensity * 100);

      // ã‚¨ãƒ•ã‚§ã‚¯ãƒˆæ¤œå‡ºå‡¦ç†
      if (detectedChannel !== -1 && !effectCooldownRef.current) {
        setLastDetectedChannel(detectedChannel);

        // åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ•ã‚§ã‚¯ãƒˆã®ç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
        if (detectedChannel < availableEffects) {
          onEffectDetected(detectedChannel);
          lastDetectedEffectRef.current = detectedChannel;
          setStatus(`ğŸ§ ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ ${detectedChannel + 1} ã‚’æ¤œå‡º`);
        } else {
          setStatus(
            `âš ï¸ æœªå¯¾å¿œã®ä¿¡å· (ãƒãƒ£ãƒ³ãƒãƒ« ${detectedChannel + 1}) ã‚’æ¤œå‡º`
          );
        }

        // ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³è¨­å®š
        effectCooldownRef.current = true;
        setTimeout(() => {
          effectCooldownRef.current = false;
        }, 500);
      }
    }, 50);
  };

  // å—ä¿¡é–‹å§‹
  const startReceiving = async () => {
    if (!audioContextRef.current) {
      const success = await requestMicrophoneAccess();
      if (!success) return;
    }

    const audioContext = audioContextRef.current;
    if (audioContext && audioContext.state === "suspended") {
      await audioContext.resume();
    }

    startDetectionLoop();
    setIsReceiving(true);
    setStatus("ğŸ§ éŸ³æ³¢ä¿¡å·ã‚’å—ä¿¡ä¸­...");
  };

  // å—ä¿¡åœæ­¢
  const stopReceiving = () => {
    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
      detectionIntervalRef.current = null;
    }

    setIsReceiving(false);
    effectCooldownRef.current = false;
    lastDetectedEffectRef.current = -1;
    setStatus("å—ä¿¡ã‚’åœæ­¢ã—ã¾ã—ãŸ");
    setDetectedFrequency(0);
    setSignalStrength(0);
    setLastDetectedChannel(-1);
  };

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      stopReceiving();
      if (microphoneRef.current) {
        microphoneRef.current.disconnect();
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
    };
  }, []);

  return (
    <div
      style={{
        position: "fixed",
        top: "50%",
        left: "50%",
        transform: "translate(-50%, -50%)",
        backgroundColor: "rgba(0, 0, 0, 0.8)",
        padding: "20px",
        borderRadius: "10px",
        color: "white",
        textAlign: "center",
        zIndex: 1000,
      }}
    >
      <div style={{marginBottom: "10px"}}>ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}</div>
      <div style={{marginBottom: "10px"}}>
        æ¤œå‡ºå‘¨æ³¢æ•°:{" "}
        {detectedFrequency > 0 ? `${detectedFrequency.toFixed(1)}Hz` : "---"}
      </div>
      <div style={{marginBottom: "10px"}}>
        ä¿¡å·å¼·åº¦: {Math.round(signalStrength)}%
      </div>
      <div style={{marginBottom: "10px"}}>
        æ¤œå‡ºãƒãƒ£ãƒ³ãƒãƒ«:{" "}
        {lastDetectedChannel >= 0 ? lastDetectedChannel + 1 : "---"}
      </div>
      <div
        style={{
          width: "200px",
          height: "10px",
          backgroundColor: "#333",
          borderRadius: "5px",
          margin: "0 auto",
        }}
      >
        <div
          style={{
            width: `${signalStrength}%`,
            height: "100%",
            backgroundColor: "#4CAF50",
            borderRadius: "5px",
            transition: "width 0.1s ease-in-out",
          }}
        />
      </div>
      <button
        onClick={isReceiving ? stopReceiving : startReceiving}
        style={{
          marginTop: "10px",
          padding: "8px 16px",
          backgroundColor: isReceiving ? "#f44336" : "#4CAF50",
          color: "white",
          border: "none",
          borderRadius: "4px",
          cursor: "pointer",
        }}
      >
        {isReceiving ? "åœæ­¢" : "é–‹å§‹"}
      </button>
    </div>
  );
}
